"""
SVM Heart Disease Predictor
---------------------------

This script trains and evaluates Support Vector Machine (SVM) models to predict heart disease
from 10 categorical health parameters. It:

1) Preprocesses data (LabelEncoder for target, OneHotEncoder for categorical features)
2) Splits data with stratification
3) Trains Linear SVM (baseline) and default RBF SVM
4) Tunes RBF SVM via GridSearchCV over C and gamma
5) Evaluates with accuracy, classification report, confusion matrix heatmap
6) Compares accuracies in a bar chart
7) Saves the tuned model and the OneHotEncoder for deployment
8) Provides an interactive live prediction function loading saved artifacts

Usage:
  - Run this script to train and evaluate models and save artifacts.
  - After training, you can perform a live prediction when prompted, or rerun and choose prediction.

Artifacts:
  - models/svm_tuned_rbf.joblib
  - models/onehot_encoder.joblib
  - outputs/confusion_matrix.png
  - outputs/model_accuracies.png
  - outputs/classification_report.txt

Author: Auto-generated by GitHub Copilot
"""

from __future__ import annotations

import os
import sys
from dataclasses import dataclass
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
)

import matplotlib

# Set non-interactive backend for reliable image saving in terminals
matplotlib.use("Agg")
import matplotlib.pyplot as plt  # noqa: E402
import seaborn as sns  # noqa: E402

try:
    import joblib  # type: ignore
except Exception:  # pragma: no cover
    # Fallback to sklearn.externals.joblib if joblib isn't separately installed (older stacks)
    from sklearn.externals import joblib  # type: ignore


# Configuration
DATA_PATH = os.path.join("Dataset", "heart_disease.csv")
MODELS_DIR = os.path.join("models")
OUTPUTS_DIR = os.path.join("outputs")
SHOW_PLOTS = False  # Set True to open figures interactively if supported
RANDOM_STATE = 42
TEST_SIZE = 0.2


# The 10 categorical features to use (must exist in dataset)
FEATURE_COLS: List[str] = [
    "Exercise Habits",
    "Smoking",
    "Family Heart Disease",
    "Diabetes",
    "High Blood Pressure",
    "Low HDL Cholesterol",
    "High LDL Cholesterol",
    "Alcohol Consumption",
    "Stress Level",
    "Sugar Consumption",
]

# Target column
TARGET_COL = "Heart Disease Status"


@dataclass
class ModelArtifacts:
    """Container for trained model and encoder artifacts.

    Attributes:
            encoder: Fitted OneHotEncoder for categorical features.
            linear_svm: Trained baseline linear SVC.
            rbf_svm_default: Trained default RBF SVC (untuned).
            rbf_svm_tuned: Best RBF SVC after GridSearchCV tuning.
    """

    encoder: OneHotEncoder
    linear_svm: SVC
    rbf_svm_default: SVC
    rbf_svm_tuned: SVC


def ensure_dirs() -> None:
    """Ensure output directories exist."""
    os.makedirs(MODELS_DIR, exist_ok=True)
    os.makedirs(OUTPUTS_DIR, exist_ok=True)


def load_data(csv_path: str) -> pd.DataFrame:
    """Load the dataset from CSV.

    Args:
            csv_path: Path to the CSV file.

    Returns:
            Loaded pandas DataFrame.
    """
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"Dataset not found at {csv_path}")
    df = pd.read_csv(csv_path)
    return df


def preprocess(df: pd.DataFrame) -> Tuple[pd.DataFrame, np.ndarray, LabelEncoder]:
    """Preprocess the dataset: select features, encode target and clean.

    Steps:
      - Select the 10 categorical feature columns.
      - Fill missing feature values with 'Unknown' to keep rows usable.
      - Encode target with LabelEncoder as required (No=0, Yes=1 if present).

    Args:
            df: Raw dataframe.

    Returns:
            X_df: DataFrame with only the selected categorical features (string dtype).
            y: Encoded target as 0/1 numpy array.
            le: Fitted LabelEncoder for target (for reference/logging).
    """
    missing = [c for c in FEATURE_COLS + [TARGET_COL] if c not in df.columns]
    if missing:
        raise KeyError(
            "Missing expected columns: " + ", ".join(missing)
        )

    X_df = df[FEATURE_COLS].copy()

    # Normalize to string and handle missing as a category
    for col in FEATURE_COLS:
        X_df[col] = X_df[col].astype("string").fillna("Unknown").str.strip()

    # Target encoding via LabelEncoder
    y_raw = df[TARGET_COL].astype("string").fillna("Unknown").str.strip()
    le = LabelEncoder()
    y = le.fit_transform(y_raw)

    # Optional: log the mapping for clarity
    # Example: classes_ like ['No', 'Yes'] -> 0, 1
    mapping_info = {cls: int(idx) for idx, cls in enumerate(le.classes_)}
    print(f"LabelEncoder classes mapping (class -> int): {mapping_info}")

    return X_df, y, le


def split_data(X: pd.DataFrame, y: np.ndarray) -> Tuple[pd.DataFrame, pd.DataFrame, np.ndarray, np.ndarray]:
    """Train/test split with stratification.

    Args:
            X: Features dataframe.
            y: Encoded target array.

    Returns:
            X_train, X_test, y_train, y_test
    """
    return train_test_split(
        X,
        y,
        test_size=TEST_SIZE,
        random_state=RANDOM_STATE,
        stratify=y,
    )


def fit_onehot_encoder(X_train: pd.DataFrame) -> OneHotEncoder:
    """Fit OneHotEncoder on training features.

    Uses handle_unknown='ignore' to avoid runtime errors on unseen categories.

    Args:
            X_train: Training features dataframe.

    Returns:
            Fitted OneHotEncoder instance.
    """
    # Use sparse_output=False for scikit-learn >= 1.2 (replaces deprecated 'sparse')
    enc = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    enc.fit(X_train)
    return enc


def transform_features(encoder: OneHotEncoder, X: pd.DataFrame) -> np.ndarray:
    """Transform features using fitted OneHotEncoder.

    Args:
            encoder: Fitted OneHotEncoder.
            X: Dataframe of categorical features.

    Returns:
            Dense numpy array of encoded features.
    """
    return encoder.transform(X)


def train_svms(X_train_enc: np.ndarray, y_train: np.ndarray) -> Tuple[SVC, SVC]:
    """Train baseline linear SVM and default RBF SVM.

    Args:
            X_train_enc: One-hot encoded training features.
            y_train: Training labels.

    Returns:
            (linear_svm, rbf_svm_default)
    """
    linear = SVC(kernel="linear", random_state=RANDOM_STATE)
    linear.fit(X_train_enc, y_train)

    rbf_default = SVC(kernel="rbf", random_state=RANDOM_STATE)
    rbf_default.fit(X_train_enc, y_train)

    return linear, rbf_default


def tune_rbf_svm(X_train_enc: np.ndarray, y_train: np.ndarray) -> Tuple[SVC, Dict[str, float], float]:
    """Tune RBF SVM with GridSearchCV over C and gamma.

    Args:
            X_train_enc: Encoded training features.
            y_train: Training labels.

    Returns:
            best_estimator: Best SVC model found.
            best_params: Dict with best C and gamma.
            best_cv_score: Best cross-validation accuracy.
    """
    fast = os.environ.get("FAST_TRAIN", "0").strip() in {
        "1", "true", "True", "YES", "yes"}
    if fast:
        # Smaller grid and fewer folds for quicker iteration
        param_grid = {
            "C": [0.1, 1, 10, 100],
            "gamma": ["scale", "auto", 0.01, 0.1],
        }
        cv_folds = 3
    else:
        param_grid = {
            "C": [0.1, 1, 10, 100, 1000],
            "gamma": ["scale", "auto", 0.01, 0.1, 1, 10],
        }
        cv_folds = 5
    grid = GridSearchCV(
        SVC(kernel="rbf", random_state=RANDOM_STATE),
        param_grid=param_grid,
        scoring="accuracy",
        cv=cv_folds,
        n_jobs=-1,
        verbose=0,
    )
    grid.fit(X_train_enc, y_train)
    best_estimator: SVC = grid.best_estimator_
    best_params = grid.best_params_
    best_cv_score = grid.best_score_
    return best_estimator, best_params, float(best_cv_score)


def evaluate_model(model: SVC, X_test_enc: np.ndarray, y_test: np.ndarray) -> Tuple[float, str, np.ndarray]:
    """Evaluate a trained model.

    Args:
            model: Trained SVC.
            X_test_enc: Encoded test features.
            y_test: Test labels.

    Returns:
            accuracy: Test accuracy.
            report: Classification report string.
            cm: Confusion matrix as ndarray.
    """
    y_pred = model.predict(X_test_enc)
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(
        y_test, y_pred, target_names=["No", "Yes"], digits=4)
    cm = confusion_matrix(y_test, y_pred)
    return float(acc), report, cm


def plot_confusion_matrix(cm: np.ndarray, title: str, save_path: str) -> None:
    """Save a heatmap for the confusion matrix."""
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
                xticklabels=["No", "Yes"], yticklabels=["No", "Yes"])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(title)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    if SHOW_PLOTS:
        plt.show()
    plt.close()


def plot_model_accuracies(accs: Dict[str, float], save_path: str) -> None:
    """Save a bar chart comparing model accuracies.

    Args:
            accs: Mapping of model name to accuracy.
            save_path: File path to save the bar chart.
    """
    names = list(accs.keys())
    values = [accs[n] for n in names]
    plt.figure(figsize=(7, 4))
    bars = plt.bar(names, values, color=["#6baed6", "#9ecae1", "#2171b5"])
    plt.ylim(0, 1)
    plt.ylabel("Accuracy")
    plt.title("Model Accuracy Comparison (Test Set)")
    for bar, val in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width() / 2, val + 0.01, f"{val:.3f}",
                 ha="center", va="bottom")
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    if SHOW_PLOTS:
        plt.show()
    plt.close()


def save_artifacts(model: SVC, encoder: OneHotEncoder) -> Tuple[str, str]:
    """Save the tuned model and encoder to disk.

    Returns:
            Tuple of (model_path, encoder_path)
    """
    ensure_dirs()
    model_path = os.path.join(MODELS_DIR, "svm_tuned_rbf.joblib")
    enc_path = os.path.join(MODELS_DIR, "onehot_encoder.joblib")
    joblib.dump(model, model_path)
    joblib.dump(encoder, enc_path)
    print(f"Saved tuned model to: {model_path}")
    print(f"Saved OneHotEncoder to: {enc_path}")
    return model_path, enc_path


def normalize_input(value: str) -> str:
    """Normalize user input for categorical values (case and common shorthands)."""
    v = (value or "").strip()
    # Common boolean shorthands
    if v.lower() in {"y", "yes"}:
        return "Yes"
    if v.lower() in {"n", "no"}:
        return "No"
    # Title case typical categories like low/medium/high/none
    if v.lower() in {"low", "medium", "high", "none", "unknown"}:
        return v.capitalize()
    return v


def live_prediction(model_path: str, encoder_path: str) -> None:
    """Interactive prediction using saved encoder and model.

    Prompts the user to enter the 10 feature values, applies the saved
    OneHotEncoder transform, and prints a Yes/No prediction.

    Args:
            model_path: Path to saved tuned SVM model.
            encoder_path: Path to saved OneHotEncoder.
    """
    if not (os.path.exists(model_path) and os.path.exists(encoder_path)):
        print("Saved model/encoder not found. Please train the model first.")
        return

    encoder: OneHotEncoder = joblib.load(encoder_path)
    model: SVC = joblib.load(model_path)

    # Derive available categories per feature from encoder if possible
    feature_names_in = list(
        getattr(encoder, "feature_names_in_", FEATURE_COLS))
    categories = getattr(encoder, "categories_", None)
    allowed_per_feature: Dict[str, List[str]] = {}
    if categories is not None and len(categories) == len(feature_names_in):
        for fname, cats in zip(feature_names_in, categories):
            allowed_per_feature[fname] = sorted(
                [str(c) for c in cats if str(c) != "nan"]) + ["Unknown"]

    print("\nProvide inputs for live prediction. Press Enter to accept suggested range or type your value.")
    user_row: Dict[str, str] = {}
    for fname in feature_names_in:
        hint = ""
        if fname in allowed_per_feature:
            hint = f" (options: {', '.join(allowed_per_feature[fname])})"
        val = input(f"{fname}{hint}: ")
        val = normalize_input(val)
        if not val:
            val = "Unknown"
        user_row[fname] = val

    X_user_df = pd.DataFrame([user_row], columns=feature_names_in)
    X_user_enc = encoder.transform(X_user_df)
    pred = int(model.predict(X_user_enc)[0])

    if pred == 1:
        print("\nPrediction: HEART DISEASE DETECTED (Yes)")
    else:
        print("\nPrediction: NO HEART DISEASE DETECTED (No)")


def main(argv: List[str] | None = None) -> int:
    """Entry point to train, evaluate, and optionally run live prediction.

    Returns:
            Process exit code (0 for success, non-zero for errors).
    """
    argv = argv or sys.argv[1:]
    ensure_dirs()

    # 1) Load and preprocess
    print("Loading data...")
    df = load_data(DATA_PATH)
    X_df, y, le = preprocess(df)
    print(
        f"Dataset size: {len(df)} rows. Class balance: {dict(zip(le.classes_, np.bincount(y)))}")

    # 2) Split
    print("Splitting data (stratified)...")
    X_train, X_test, y_train, y_test = split_data(X_df, y)

    # 3) Fit encoder and transform
    print("Fitting OneHotEncoder and transforming features...")
    encoder = fit_onehot_encoder(X_train)
    X_train_enc = transform_features(encoder, X_train)
    X_test_enc = transform_features(encoder, X_test)

    # 4) Train baseline models
    print("Training baseline Linear SVM and default RBF SVM...")
    linear_svm, rbf_svm_default = train_svms(X_train_enc, y_train)

    # 5) Evaluate baselines
    print("Evaluating baseline models on test set...")
    acc_linear, _, _ = evaluate_model(linear_svm, X_test_enc, y_test)
    acc_rbf_default, _, _ = evaluate_model(rbf_svm_default, X_test_enc, y_test)
    print(f"Linear SVM Test Accuracy: {acc_linear:.4f}")
    print(f"Default RBF SVM Test Accuracy: {acc_rbf_default:.4f}")

    # 6) Hyperparameter tuning for RBF
    print("Tuning RBF SVM with GridSearchCV (C, gamma)...")
    rbf_svm_tuned, best_params, best_cv = tune_rbf_svm(X_train_enc, y_train)
    print(f"Best RBF params: {best_params} with CV accuracy: {best_cv:.4f}")

    # 7) Final evaluation on held-out test set
    print("Evaluating tuned RBF SVM on test set...")
    acc_rbf_tuned, report, cm = evaluate_model(
        rbf_svm_tuned, X_test_enc, y_test)
    print(f"Tuned RBF SVM Test Accuracy: {acc_rbf_tuned:.4f}")
    print("\nClassification Report (Tuned RBF):\n" + report)

    # Save report
    ensure_dirs()
    report_path = os.path.join(OUTPUTS_DIR, "classification_report.txt")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("Classification Report (Tuned RBF)\n")
        f.write("Best Params: " + str(best_params) + "\n\n")
        f.write(report)
    print(f"Saved classification report to: {report_path}")

    # 8) Visualizations
    cm_path = os.path.join(OUTPUTS_DIR, "confusion_matrix.png")
    plot_confusion_matrix(cm, "Confusion Matrix - Tuned RBF SVM", cm_path)
    print(f"Saved confusion matrix heatmap to: {cm_path}")

    accs = {
        "Linear SVM": acc_linear,
        "RBF SVM (Default)": acc_rbf_default,
        "RBF SVM (Tuned)": acc_rbf_tuned,
    }
    accs_path = os.path.join(OUTPUTS_DIR, "model_accuracies.png")
    plot_model_accuracies(accs, accs_path)
    print(f"Saved model accuracy comparison chart to: {accs_path}")

    # 9) Save artifacts
    model_path, enc_path = save_artifacts(rbf_svm_tuned, encoder)

    # 10) Offer live prediction
    # Offer live prediction only if running in an interactive terminal
    if sys.stdin is not None and sys.stdin.isatty():
        choice = input("\nDo you want to make a live prediction now? (y/n): ")
        if choice.strip().lower() in {"y", "yes"}:
            live_prediction(model_path, enc_path)
        else:
            print("Live prediction skipped. You can rerun the script anytime to predict.")
    else:
        print("\nNon-interactive environment detected; skipping live prediction prompt.")

    print("\nAll done.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
